{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras + Flask for REST api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import flask\n",
    "import io\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize our Flask application and the Keras model\n",
    "app = flask.Flask(__name__)\n",
    "model = None\n",
    "english_tokenizer = None\n",
    "french_tokenizer = None\n",
    "y_id_to_word = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading our model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_translation_model():\n",
    "    # load the pre-trained Keras model \n",
    "    global model\n",
    "    global english_tokenizer\n",
    "    global french_tokenizer\n",
    "    global y_id_to_word\n",
    "    model = load_model('translation.h5')\n",
    "    # loading\n",
    "    with open('english_tokenizer.pickle', 'rb') as handle:\n",
    "        english_tokenizer = pickle.load(handle)\n",
    "    with open('french_tokenizer.pickle', 'rb') as handle:\n",
    "        french_tokenizer = pickle.load(handle)\n",
    "    y_id_to_word = {value: key for key, value in french_tokenizer.word_index.items()}\n",
    "    y_id_to_word[0] = '<PAD>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the text for input to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_text(sentence):\n",
    "    sentence = [english_tokenizer.word_index[word] for word in sentence.split()]\n",
    "    sentence = pad_sequences([sentence], maxlen=15, padding='post')\n",
    "    sentence = np.array(sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting numbers back to words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logits_to_text(logits, tokenizer = french_tokenizer):\n",
    "    \"\"\"\n",
    "    Turn logits from a neural network into text using the tokenizer\n",
    "    :param logits: Logits from a neural network\n",
    "    :param tokenizer: Keras Tokenizer fit on the labels\n",
    "    :return: String that represents the text of the logits\n",
    "    \"\"\"\n",
    "    index_to_words = y_id_to_word\n",
    "\n",
    "    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route(\"/predict\")\n",
    "def predict():\n",
    "    data = {\"success\": False}\n",
    "    sentence = flask.request.args.get('sentence')\n",
    "    print(sentence)\n",
    "    sentence = prepare_text(sentence)\n",
    "    sentence = model.predict(sentence,1)\n",
    "    sentence = logits_to_text(sentence)\n",
    "    data[\"success\"] = True\n",
    "    data[\"prediction\"] = sentence\n",
    "    # return the data dictionary as a JSON response\n",
    "    return flask.jsonify(data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Loading Keras model and Flask starting server...please wait until server has fully started\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: Do not use the development server in a production environment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "[2018-10-20 19:27:05,267] ERROR in app: Exception on /predict [GET]\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/avinsharma/miniconda3/envs/keras/lib/python3.6/site-packages/flask/app.py\", line 2292, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/Users/avinsharma/miniconda3/envs/keras/lib/python3.6/site-packages/flask/app.py\", line 1815, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/Users/avinsharma/miniconda3/envs/keras/lib/python3.6/site-packages/flask/app.py\", line 1718, in handle_user_exception\n",
      "    reraise(exc_type, exc_value, tb)\n",
      "  File \"/Users/avinsharma/miniconda3/envs/keras/lib/python3.6/site-packages/flask/_compat.py\", line 35, in reraise\n",
      "    raise value\n",
      "  File \"/Users/avinsharma/miniconda3/envs/keras/lib/python3.6/site-packages/flask/app.py\", line 1813, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/Users/avinsharma/miniconda3/envs/keras/lib/python3.6/site-packages/flask/app.py\", line 1799, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"<ipython-input-6-e17f5ba544c6>\", line 7, in predict\n",
      "    sentence = model.predict(sentence,1)\n",
      "  File \"/Users/avinsharma/miniconda3/envs/keras/lib/python3.6/site-packages/keras/engine/training.py\", line 1164, in predict\n",
      "    self._make_predict_function()\n",
      "  File \"/Users/avinsharma/miniconda3/envs/keras/lib/python3.6/site-packages/keras/engine/training.py\", line 554, in _make_predict_function\n",
      "    **kwargs)\n",
      "  File \"/Users/avinsharma/miniconda3/envs/keras/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 2744, in function\n",
      "    return Function(inputs, outputs, updates=updates, **kwargs)\n",
      "  File \"/Users/avinsharma/miniconda3/envs/keras/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 2546, in __init__\n",
      "    with tf.control_dependencies(self.outputs):\n",
      "  File \"/Users/avinsharma/miniconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 5002, in control_dependencies\n",
      "    return get_default_graph().control_dependencies(control_inputs)\n",
      "  File \"/Users/avinsharma/miniconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 4541, in control_dependencies\n",
      "    c = self.as_graph_element(c)\n",
      "  File \"/Users/avinsharma/miniconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3488, in as_graph_element\n",
      "    return self._as_graph_element_locked(obj, allow_tensor, allow_operation)\n",
      "  File \"/Users/avinsharma/miniconda3/envs/keras/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3567, in _as_graph_element_locked\n",
      "    raise ValueError(\"Tensor %s is not an element of this graph.\" % obj)\n",
      "ValueError: Tensor Tensor(\"dense_7/truediv:0\", shape=(?, 21, 344), dtype=float32) is not an element of this graph.\n",
      "127.0.0.1 - - [20/Oct/2018 19:27:05] \"\u001b[1m\u001b[35mGET /predict?sentence=banana HTTP/1.1\u001b[0m\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "banana\n"
     ]
    }
   ],
   "source": [
    "# if this is the main thread of execution first load the model and\n",
    "# then start the server\n",
    "if __name__ == \"__main__\":\n",
    "    print((\"* Loading Keras model and Flask starting server...\"\n",
    "        \"please wait until server has fully started\"))\n",
    "    load_translation_model()\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(english_tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
